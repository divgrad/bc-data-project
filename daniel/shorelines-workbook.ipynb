{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shore Line Feature Detection Worksheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data available:\n",
    "- .txt file containing longitude, latitude, height, red, green, blue values\n",
    "- several .tif orthophotos\n",
    "\n",
    "With no labeled data our goals are:\n",
    "- provide an unsupervised clustering algorithm to extract distinct features from .txt file including the above data\n",
    "- give suggestions on how this feature extraction algorithm can be used to label data with human intervention\n",
    "- reduce the need for humans to trace out boundaries of distinct features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Management (scalable if system has more storage and memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step is to import the relevant python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn import svm\n",
    "import seaborn as sns\n",
    "\n",
    "import scipy as sp\n",
    "import scipy.sparse as sps\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we select a random subsample of the original data containing 10,000,000 data points (roughly $1/6^{\\text{th}}$ of the total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain a shuffled data set from the original text file using bash commands\n",
    "!shuf -n 10000000 /home/divgrad/data/4-Vadeboncoeur/davis-bay.txt > /home/divgrad/bcdata-project-temp/sample-temp.txt\n",
    "data = pd.read_csv('/home/divgrad/bcdata-project-temp/sample-temp.txt',sep=\" \", header=None)\n",
    "!rm /home/divgrad/bcdata-project-temp/sample-temp.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each data poitn is represented by a row and each columnb represents: longitude, latitude, heigh [m], red, green, blue.\n",
    "The last three rows are not used (they likely represent some sort of angle and are not necessary for this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.columns = ['lon', 'lat', 'z', 'r', 'g', 'b', '?', '?', '?']\n",
    "\n",
    "# extract height data from pandas dataframe\n",
    "lon, lat = data['lon'].values, data['lat'].values\n",
    "z = data['z'].values\n",
    "rgb = data[['r','g','b']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level One: Clustering With Respect to Height Variation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data list is unordered, we instead use a nearest neighbour algorithm to determine which points are neighbours of each other. This is stored in a connectivity matrix, A, from which we can now extract useful information such as the average height in each neighbourhood as well as the standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we work only with the first million data entries (computation on all 10,000,000 too computationally intensive)\n",
    "lon_1, lat_1 = lon[:1000000], lat[:1000000]\n",
    "z = z[:1000000]\n",
    "rgb_1 = rgb[:1000000,:]\n",
    "\n",
    "# radius around each point in which we will be calculating height variation\n",
    "neighbor_radius = np.sqrt((lon_1.max()-lon_1.min())**2 + (lat_1.max()-lat_1.min())**2)/5000\n",
    "\n",
    "# for each point find all neighbors within specified distance away\n",
    "nn = NearestNeighbors(radius=neighbor_radius,metric='euclidean')\n",
    "nn.fit(np.column_stack((lon_1,lat_1)))\n",
    "\n",
    "# connectivity matrix: 0 = not a neighbor | 1 = a neighbor\n",
    "A = nn.radius_neighbors_graph()\n",
    "\n",
    "# this vector and diagonal matrices give you 1/(number of neighbourrs including self)\n",
    "q = 1/(np.squeeze(np.asarray(A.sum(axis=1)))+1)\n",
    "Q = sps.diags(q)\n",
    "A_ave = Q.dot(A) + sps.eye(Q.shape[0])\n",
    "\n",
    "# matrix multiplication with z gives average height of neighbors for each point\n",
    "z_ave = A_ave.dot(z)\n",
    "\n",
    "# compute the standrad deviation of all neighbors for each point (including self)\n",
    "z_std = np.sqrt(A_ave.dot((z-z_ave)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use mini-batch k-means to go through the data and perform the k-means clustering algorithm. Our choice of 5 clusters was found through visual trial and error as well as comparison of color and heigh distributions. More work can (and should) be done in the future to determine optimal number of clusters. An ideal system would continue to increase the number of clusters until some stopping criteria is met. Some suggestions for future work include:\n",
    "- developing a quantitative way to measure differences in spatial variation among clusters, and stop increasing the number of clusters when this difference is sufficiently small.\n",
    "- research regions where algorithm will be applied to determine characteristics of the land and choose the number of clusters before hand. Then compare the clusters with the expected characteristics of the land."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50000\n",
    "num_clusters = 5\n",
    "\n",
    "# create mini batch k-means object\n",
    "mbk_zstd = MiniBatchKMeans(init='k-means++', n_clusters=num_clusters, batch_size=batch_size,\n",
    "                      n_init=10, max_no_improvement=10, verbose=0)\n",
    "\n",
    "# fit the 1,000,000 standard deviation in height data with the k-means model\n",
    "mbk_zstd.fit(z_std.reshape(-1,1));\n",
    "\n",
    "# extract the labels: 0, 1, 2, 3, 4\n",
    "mbk_zstd_labels = mbk_zstd.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbk_zstd.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the index sampling in this piece of code is for visualization purposes only; we have to avoid plotting 1,000,000 points!\n",
    "smpl_idx_1 = np.random.choice(np.arange(len(lon_1)), 150000, replace=False)\n",
    "\n",
    "smpl_lon_1, smpl_lat_1  = lon[smpl_idx_1], lat[smpl_idx_1]\n",
    "smpl_z_1 = z[smpl_idx_1]\n",
    "smpl_rgb_1 = rgb[smpl_idx_1]\n",
    "smpl_rgb_1_scaled = smpl_rgb_1/255\n",
    "smpl_labels_1 = mbk_zstd_labels[smpl_idx_1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of Height Standard Deviation Clustering Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.scatter(smpl_lon_1,smpl_lat_1,c=smpl_rgb_1_scaled,s=3,lw=0);\n",
    "plt.axis('scaled')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Color Coded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.scatter(smpl_lon_1,smpl_lat_1,c=smpl_labels_1,s=3,lw=0,cmap='plasma');\n",
    "plt.axis('scaled')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Label 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_label = 0\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.scatter(smpl_lon_1[smpl_labels_1==curr_label],smpl_lat_1[smpl_labels_1==curr_label],c=smpl_rgb_1_scaled[smpl_labels_1==curr_label,:],s=3,lw=0);\n",
    "plt.axis('scaled')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster Label 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_label = 1\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.scatter(smpl_lon_1[smpl_labels_1==curr_label],smpl_lat_1[smpl_labels_1==curr_label],c=smpl_rgb_1_scaled[smpl_labels_1==curr_label,:],s=3,lw=0);\n",
    "plt.axis('scaled')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Label 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_label = 2\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.scatter(smpl_lon_1[smpl_labels_1==curr_label],smpl_lat_1[smpl_labels_1==curr_label],c=smpl_rgb_1_scaled[smpl_labels_1==curr_label,:],s=3,lw=0);\n",
    "plt.axis('scaled')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Label 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_label = 3\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.scatter(smpl_lon_1[smpl_labels_1==curr_label],smpl_lat_1[smpl_labels_1==curr_label],c=smpl_rgb_1_scaled[smpl_labels_1==curr_label,:],s=3,lw=0);\n",
    "plt.axis('scaled')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Label 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_label = 4\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.scatter(smpl_lon_1[smpl_labels_1==curr_label],smpl_lat_1[smpl_labels_1==curr_label],c=smpl_rgb_1_scaled[smpl_labels_1==curr_label,:],s=3,lw=0);\n",
    "plt.axis('scaled')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Height and Colour (RGB) Variability in Each Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Height Variability</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,9))\n",
    "\n",
    "for curr_label in range(num_clusters):\n",
    "    plt.subplot(num_clusters,1,curr_label+1)\n",
    "    plt.hist(z[mbk_zstd_labels==curr_label],bins='auto',color='0.5',lw=0,normed=True)\n",
    "    plt.xlim((np.min(z),np.max(z)))\n",
    "    \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histograms for clusters 1, 2, and 3 suggest further clustering could be done. This is where a cluster number selection algorithm would be most useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>RGB Variability</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,9))\n",
    "\n",
    "for curr_label in range(num_clusters):\n",
    "    plt.subplot(num_clusters,3,3*curr_label+1)\n",
    "    plt.hist(rgb_1[mbk_zstd_labels==curr_label,0],bins=255,color='r',lw=0,normed=True)\n",
    "    plt.xlim((0,255))\n",
    "    plt.subplot(num_clusters,3,3*curr_label+2)\n",
    "    plt.hist(rgb_1[mbk_zstd_labels==curr_label,1],bins=255,color='g',lw=0,normed=True)\n",
    "    plt.xlim((0,255))\n",
    "    plt.subplot(num_clusters,3,3*curr_label+3)\n",
    "    plt.hist(rgb_1[mbk_zstd_labels==curr_label,2],bins=255,color='b',lw=0,normed=True)\n",
    "    plt.xlim((0,255))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RGB histograms indicate that there is potential for a lot of clustering with respect to RGB values within each level one cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level Two: RGB Sub-Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def variation_color(r):\n",
    "    suma = r[:,0]+r[:,1]+r[:,2]\n",
    "    vector1 = r[:,0]/suma\n",
    "    vector2 = r[:,1]/suma\n",
    "    vector3 = r[:,2]/suma\n",
    "    \n",
    "    return np.hstack([[vector1,vector2,vector3]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh = KNeighborsClassifier(radius=1e-5)\n",
    "neigh.fit(np.column_stack((lon_1, lat_1)),mbk_zstd_labels);\n",
    "\n",
    "space = np.column_stack((lon,lat))\n",
    "labels = neigh.predict(space)\n",
    "data1 = np.column_stack((lon,lat,rgb))\n",
    "\n",
    "data1_0 = np.array([j for i,j in enumerate(data1) if labels[i] == 0])\n",
    "cluster_0 = data1_0[:,[2,3,4]]\n",
    "lon_0 = data1_0[:,0]\n",
    "lat_0 = data1_0[:,1]\n",
    "data1_1 = np.array([m for l,m in enumerate(data1) if labels[l] == 1])\n",
    "cluster_1 = data1_1[:,[2,3,4]]\n",
    "lon_1 = data1_1[:,0]\n",
    "lat_1 = data1_1[:,1]\n",
    "data1_2 = np.array([r for s,r in enumerate(data1) if labels[s] == 2])\n",
    "cluster_2 = data1_2[:,[2,3,4]]\n",
    "lon_2 = data1_2[:,0]\n",
    "lat_2 = data1_2[:,1]\n",
    "data1_3 = np.array([u for w,u in enumerate(data1) if labels[w] == 3])\n",
    "cluster_3 = data1_3[:,[2,3,4]]\n",
    "lon_3 = data1_3[:,0]\n",
    "lat_3 = data1_3[:,1]\n",
    "data1_4 = np.array([p for q,p in enumerate(data1) if labels[q] == 4])\n",
    "cluster_4 = data1_4[:,[2,3,4]]\n",
    "lon_4 = data1_4[:,0]\n",
    "lat_4 = data1_4[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster 0 - Subclustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50000\n",
    "num_clusters = 5\n",
    "\n",
    "mbk_rgb0 = MiniBatchKMeans(init='k-means++', n_clusters=num_clusters, batch_size=batch_size,\n",
    "                      n_init=10, max_no_improvement=10, verbose=0)\n",
    "\n",
    "cluster_00 = variation_color(np.array(cluster_0));\n",
    "\n",
    "mbk_rgb0.fit(np.array(cluster_00))\n",
    "mbk_labels = mbk_rgb0.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smpl_idx = np.random.choice(np.arange(len(cluster_0)), 150000, replace=False)\n",
    "smpl_lon, smpl_lat, smpl_rgb  = np.array(lon_0)[smpl_idx], np.array(lat_0)[smpl_idx], np.array(cluster_0)[smpl_idx]\n",
    "smpl_labels = mbk_labels[smpl_idx]\n",
    "\n",
    "cluster_01 = np.array(cluster_0)/255\n",
    "smpl_rgb = np.array(cluster_0)[smpl_idx]\n",
    "smpl_rgb_01 = cluster_01[smpl_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Cluster 0 (Original) </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.scatter(smpl_lon,smpl_lat,c=smpl_rgb_01,s=3,lw=0)\n",
    "plt.axis('scaled')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Cluster 0 - 0</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_label = 0\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.scatter(smpl_lon[smpl_labels==curr_label],smpl_lat[smpl_labels==curr_label],c=smpl_rgb_01[smpl_labels==curr_label,:],s=3,lw=0)\n",
    "plt.axis('scaled')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Cluster 0 - 1</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_label = 1\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.scatter(smpl_lon[smpl_labels==curr_label],smpl_lat[smpl_labels==curr_label],c=smpl_rgb_01[smpl_labels==curr_label,:],s=3,lw=0)\n",
    "plt.axis('scaled')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Cluster 0 - 2</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_label = 2\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.scatter(smpl_lon[smpl_labels==curr_label],smpl_lat[smpl_labels==curr_label],c=smpl_rgb_01[smpl_labels==curr_label,:],s=3,lw=0)\n",
    "plt.axis('scaled')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Cluster 0 - 3</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_label = 3\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.scatter(smpl_lon[smpl_labels==curr_label],smpl_lat[smpl_labels==curr_label],c=smpl_rgb_01[smpl_labels==curr_label,:],s=3,lw=0)\n",
    "plt.axis('scaled')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Cluster 0 - 4</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_label = 4\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.scatter(smpl_lon[smpl_labels==curr_label],smpl_lat[smpl_labels==curr_label],c=smpl_rgb_01[smpl_labels==curr_label,:],s=3,lw=0)\n",
    "plt.axis('scaled')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color distribution for Cluster 0 Subclustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_label = 0\n",
    "\n",
    "plt.figure(figsize=(15,9))\n",
    "\n",
    "for curr_label in range(num_clusters):\n",
    "    plt.subplot(num_clusters,3,3*curr_label+1)\n",
    "    plt.hist(smpl_rgb[smpl_labels==curr_label,0],bins=255,color='r',lw=0,normed=True)\n",
    "    plt.xlim((0,255))\n",
    "    plt.subplot(num_clusters,3,3*curr_label+2)\n",
    "    plt.hist(smpl_rgb[smpl_labels==curr_label,1],bins=255,color='g',lw=0,normed=True)\n",
    "    plt.xlim((0,255))\n",
    "    plt.subplot(num_clusters,3,3*curr_label+3)\n",
    "    plt.hist(smpl_rgb[smpl_labels==curr_label,2],bins=255,color='b',lw=0,normed=True)\n",
    "    plt.xlim((0,255))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster 1 - Subclustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50000\n",
    "num_clusters = 5\n",
    "\n",
    "mbk_rgb1 = MiniBatchKMeans(init='k-means++', n_clusters=num_clusters, batch_size=batch_size,\n",
    "                      n_init=10, max_no_improvement=10, verbose=0)\n",
    "\n",
    "cluster_11 = variation_color(np.array(cluster_1));\n",
    "\n",
    "mbk_rgb1.fit(np.array(cluster_00))\n",
    "mbk_labels = mbk_rgb1.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smpl_idx = np.random.choice(np.arange(len(cluster_1)), 150000, replace=False)\n",
    "smpl_lon, smpl_lat, smpl_rgb  = np.array(lon_1)[smpl_idx], np.array(lat_1)[smpl_idx], np.array(cluster_1)[smpl_idx]\n",
    "smpl_labels = mbk_labels[smpl_idx]\n",
    "\n",
    "cluster_11 = np.array(cluster_1)/255\n",
    "smpl_rgb = np.array(cluster_0)[smpl_idx]\n",
    "smpl_rgb_11 = cluster_11[smpl_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Cluster 0 (Original) </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.scatter(smpl_lon,smpl_lat,c=smpl_rgb_11,s=3,lw=0)\n",
    "plt.axis('scaled')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Cluster 0 - 0</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_label = 0\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.scatter(smpl_lon[smpl_labels==curr_label],smpl_lat[smpl_labels==curr_label],c=smpl_rgb_11[smpl_labels==curr_label,:],s=3,lw=0)\n",
    "plt.axis('scaled')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Cluster 0 - 1</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_label = 1\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.scatter(smpl_lon[smpl_labels==curr_label],smpl_lat[smpl_labels==curr_label],c=smpl_rgb_11[smpl_labels==curr_label,:],s=3,lw=0)\n",
    "plt.axis('scaled')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Cluster 0 - 2</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_label = 2\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.scatter(smpl_lon[smpl_labels==curr_label],smpl_lat[smpl_labels==curr_label],c=smpl_rgb_11[smpl_labels==curr_label,:],s=3,lw=0)\n",
    "plt.axis('scaled')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Cluster 0 - 3</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_label = 3\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.scatter(smpl_lon[smpl_labels==curr_label],smpl_lat[smpl_labels==curr_label],c=smpl_rgb_11[smpl_labels==curr_label,:],s=3,lw=0)\n",
    "plt.axis('scaled')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Cluster 0 - 4</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_label = 4\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.scatter(smpl_lon[smpl_labels==curr_label],smpl_lat[smpl_labels==curr_label],c=smpl_rgb_11[smpl_labels==curr_label,:],s=3,lw=0)\n",
    "plt.axis('scaled')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Color distribution for Cluster 0 Subclustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_label = 0\n",
    "\n",
    "plt.figure(figsize=(15,9))\n",
    "\n",
    "for curr_label in range(num_clusters):\n",
    "    plt.subplot(num_clusters,3,3*curr_label+1)\n",
    "    plt.hist(smpl_rgb[smpl_labels==curr_label,0],bins=255,color='r',lw=0,normed=True)\n",
    "    plt.xlim((0,255))\n",
    "    plt.subplot(num_clusters,3,3*curr_label+2)\n",
    "    plt.hist(smpl_rgb[smpl_labels==curr_label,1],bins=255,color='g',lw=0,normed=True)\n",
    "    plt.xlim((0,255))\n",
    "    plt.subplot(num_clusters,3,3*curr_label+3)\n",
    "    plt.hist(smpl_rgb[smpl_labels==curr_label,2],bins=255,color='b',lw=0,normed=True)\n",
    "    plt.xlim((0,255))\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
